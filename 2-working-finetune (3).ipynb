{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1041ba2-837e-41d9-95fb-9d40926f6d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (4.51.3)\n",
      "Collecting bitsandbytes\n",
      "  Using cached bitsandbytes-0.46.0-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
      "Collecting datasets\n",
      "  Using cached datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting peft\n",
      "  Using cached peft-0.15.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting gitpython\n",
      "  Using cached GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: huggingface_hub in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (0.31.2)\n",
      "Requirement already satisfied: filelock in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from transformers) (2.2.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from huggingface_hub) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from huggingface_hub) (4.13.2)\n",
      "Requirement already satisfied: torch<3,>=2.2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from bitsandbytes) (2.7.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (1.14.0)\n",
      "Requirement already satisfied: networkx in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (3.3.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from triton==3.3.0->torch<3,>=2.2->bitsandbytes) (75.8.0)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Using cached pyarrow-20.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from datasets) (2.2.3)\n",
      "Collecting xxhash (from datasets)\n",
      "  Using cached xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Using cached multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface_hub)\n",
      "  Using cached fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached aiohttp-3.11.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: psutil in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from peft) (7.0.0)\n",
      "Collecting accelerate>=0.21.0 (from peft)\n",
      "  Using cached accelerate-1.8.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython)\n",
      "  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython)\n",
      "  Using cached smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached frozenlist-1.7.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached multidict-6.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached propcache-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached yarl-1.18.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (69 kB)\n",
      "Requirement already satisfied: idna>=2.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from sympy>=1.13.3->torch<3,>=2.2->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading bitsandbytes-0.46.0-py3-none-manylinux_2_24_x86_64.whl (67.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached datasets-3.6.0-py3-none-any.whl (491 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Using cached multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "Using cached peft-0.15.2-py3-none-any.whl (411 kB)\n",
      "Using cached GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
      "Using cached gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Using cached smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Using cached accelerate-1.8.1-py3-none-any.whl (365 kB)\n",
      "Using cached aiohttp-3.11.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "Using cached async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Using cached multidict-6.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (226 kB)\n",
      "Using cached yarl-1.18.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (319 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.7.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (222 kB)\n",
      "Downloading propcache-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (198 kB)\n",
      "Downloading pyarrow-20.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (42.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Installing collected packages: xxhash, smmap, pyarrow, propcache, multidict, fsspec, frozenlist, dill, async-timeout, aiohappyeyeballs, yarl, multiprocess, gitdb, aiosignal, gitpython, aiohttp, bitsandbytes, accelerate, peft, datasets\n",
      "\u001b[2K  Attempting uninstall: fsspec\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/20\u001b[0m [multidict]\n",
      "\u001b[2K    Found existing installation: fsspec 2025.3.2━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/20\u001b[0m [multidict]\n",
      "\u001b[2K    Uninstalling fsspec-2025.3.2:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/20\u001b[0m [multidict]\n",
      "\u001b[2K      Successfully uninstalled fsspec-2025.3.2━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/20\u001b[0m [multidict]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20/20\u001b[0m [datasets]/20\u001b[0m [datasets]e]s]\n",
      "\u001b[1A\u001b[2KSuccessfully installed accelerate-1.8.1 aiohappyeyeballs-2.6.1 aiohttp-3.11.12 aiosignal-1.3.2 async-timeout-5.0.1 bitsandbytes-0.46.0 datasets-3.6.0 dill-0.3.8 frozenlist-1.7.0 fsspec-2025.3.0 gitdb-4.0.12 gitpython-3.1.44 multidict-6.5.0 multiprocess-0.70.16 peft-0.15.2 propcache-0.3.2 pyarrow-20.0.0 smmap-5.0.2 xxhash-3.5.0 yarl-1.18.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: peft in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (0.15.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from peft) (2.2.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from peft) (25.0)\n",
      "Requirement already satisfied: psutil in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from peft) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from peft) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from peft) (2.7.0)\n",
      "Requirement already satisfied: transformers in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from peft) (4.51.3)\n",
      "Requirement already satisfied: tqdm in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from peft) (4.67.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from peft) (1.8.1)\n",
      "Requirement already satisfied: safetensors in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from peft) (0.5.3)\n",
      "Requirement already satisfied: huggingface_hub>=0.25.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from peft) (0.31.2)\n",
      "Requirement already satisfied: filelock in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft) (2025.3.0)\n",
      "Requirement already satisfied: requests in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.14.0)\n",
      "Requirement already satisfied: networkx in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.3.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from triton==3.3.0->torch>=1.13.0->peft) (75.8.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from requests->huggingface_hub>=0.25.0->peft) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from requests->huggingface_hub>=0.25.0->peft) (2025.1.31)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from transformers->peft) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from transformers->peft) (0.21.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: accelerate in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (1.8.1)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from accelerate) (2.2.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from accelerate) (25.0)\n",
      "Requirement already satisfied: psutil in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from accelerate) (2.7.0)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from accelerate) (0.31.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: filelock in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.0)\n",
      "Requirement already satisfied: requests in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.3.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from triton==3.3.0->torch>=2.0.0->accelerate) (75.8.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.1.31)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting git+https://github.com/huggingface/peft.git\n",
      "  Cloning https://github.com/huggingface/peft.git to /tmp/pip-req-build-rwg4ik4z\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-req-build-rwg4ik4z\n",
      "  Resolved https://github.com/huggingface/peft.git to commit bda9665bc9ad5e89279a55bc202724271bd5643b\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from peft==0.15.2.dev0) (2.2.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from peft==0.15.2.dev0) (25.0)\n",
      "Requirement already satisfied: psutil in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from peft==0.15.2.dev0) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from peft==0.15.2.dev0) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from peft==0.15.2.dev0) (2.7.0)\n",
      "Requirement already satisfied: transformers in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from peft==0.15.2.dev0) (4.51.3)\n",
      "Requirement already satisfied: tqdm in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from peft==0.15.2.dev0) (4.67.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from peft==0.15.2.dev0) (1.8.1)\n",
      "Requirement already satisfied: safetensors in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from peft==0.15.2.dev0) (0.5.3)\n",
      "Requirement already satisfied: huggingface_hub>=0.25.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from peft==0.15.2.dev0) (0.31.2)\n",
      "Requirement already satisfied: filelock in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft==0.15.2.dev0) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft==0.15.2.dev0) (2025.3.0)\n",
      "Requirement already satisfied: requests in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft==0.15.2.dev0) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft==0.15.2.dev0) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.15.2.dev0) (1.14.0)\n",
      "Requirement already satisfied: networkx in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.15.2.dev0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.15.2.dev0) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.15.2.dev0) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.15.2.dev0) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.15.2.dev0) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.15.2.dev0) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.15.2.dev0) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.15.2.dev0) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.15.2.dev0) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.15.2.dev0) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.15.2.dev0) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.15.2.dev0) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.15.2.dev0) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.15.2.dev0) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.15.2.dev0) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.15.2.dev0) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.15.2.dev0) (3.3.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from triton==3.3.0->torch>=1.13.0->peft==0.15.2.dev0) (75.8.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=1.13.0->peft==0.15.2.dev0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.15.2.dev0) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from requests->huggingface_hub>=0.25.0->peft==0.15.2.dev0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from requests->huggingface_hub>=0.25.0->peft==0.15.2.dev0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from requests->huggingface_hub>=0.25.0->peft==0.15.2.dev0) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from requests->huggingface_hub>=0.25.0->peft==0.15.2.dev0) (2025.1.31)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from transformers->peft==0.15.2.dev0) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from transformers->peft==0.15.2.dev0) (0.21.1)\n",
      "Building wheels for collected packages: peft\n",
      "  Building wheel for peft (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for peft: filename=peft-0.15.2.dev0-py3-none-any.whl size=442415 sha256=4ff470e6528d81be0df6bfd7ba38d75d882141f055d63754ed43a693a6ded886\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-4jsgo37d/wheels/d7/c7/de/1368fac8590e1b103ddc2ec2a28ad51d83aded1a3830e8a087\n",
      "Successfully built peft\n",
      "Installing collected packages: peft\n",
      "  Attempting uninstall: peft\n",
      "    Found existing installation: peft 0.15.2\n",
      "    Uninstalling peft-0.15.2:\n",
      "      Successfully uninstalled peft-0.15.2\n",
      "Successfully installed peft-0.15.2.dev0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# %% [code]\n",
    "# %% Setup: Install necessary libraries (if not already installed)\n",
    "!pip install transformers bitsandbytes datasets peft gitpython huggingface_hub\n",
    "!pip install --upgrade peft\n",
    "!pip install --upgrade accelerate\n",
    "!pip install git+https://github.com/huggingface/peft.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b78327c-6e7d-408c-b997-46378fb08ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Import libraries\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorForLanguageModeling,\n",
    ")\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "# Monkey-patch the `.to()` method of PreTrainedModel to be a no-op.\n",
    "# This prevents Accelerate from calling .to() on the 4-bit model.\n",
    "from transformers import PreTrainedModel\n",
    "PreTrainedModel.to = lambda self, *args, **kwargs: self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3377337-706b-4aca-aaa3-0996c58c599d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:476: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7281e6432d844c96b53cedfd7bb68ab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## 1. Load and Quantize the Base Mistral Model\n",
    "#\n",
    "# We load the Mistral model (here we use the \"mistralai/mistral-7b-v0.1\" model)\n",
    "# in 4‑bit mode using BitsAndBytes. The model is loaded with our Hugging Face token.\n",
    "#\n",
    "# **Note:** Replace the token and model identifier as needed.\n",
    "\n",
    "# %% Load the Mistral model and tokenizer with 4-bit quantization\n",
    "model_name = \"mistralai/mistral-7b-v0.1\"  # Change if needed\n",
    "my_token = \"hf_1111111\"  # Replace with your actual token\n",
    "\n",
    "# Define the 4-bit quantization configuration\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    ")\n",
    "\n",
    "# Load the tokenizer and set its pad token (we use the EOS token as the pad token)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Load the model in 4-bit mode.\n",
    "# We do not pass device_map=\"auto\" to avoid Accelerate dispatch (which calls .to()).\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    use_auth_token=my_token\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e58e46e0-e6d4-4d39-98bb-c8ebc9cf3dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a copy of the base model for later reference\n",
    "import copy\n",
    "base_model_copy = copy.deepcopy(model)\n",
    "\n",
    "# (Apply your LoRA fine-tuning steps here)\n",
    "from peft import LoraConfig, get_peft_model\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "model = get_peft_model(model, lora_config)\n",
    "# Patch MistralRotaryEmbedding to fix device issues in rotary embeddings.\n",
    "from transformers.models.mistral.modeling_mistral import MistralRotaryEmbedding\n",
    "\n",
    "# Save the original forward method\n",
    "original_forward = MistralRotaryEmbedding.forward\n",
    "\n",
    "def patched_forward(self, x, position_ids):\n",
    "    # Get the device from input x.\n",
    "    device = x.device\n",
    "    # If the internal inverse frequency tensor exists, move it to the same device.\n",
    "    if hasattr(self, \"inv_freq\"):\n",
    "        self.inv_freq = self.inv_freq.to(device)\n",
    "    # Also ensure that position_ids are moved to the device.\n",
    "    position_ids = position_ids.to(device)\n",
    "    # Call the original forward method.\n",
    "    return original_forward(self, x, position_ids)\n",
    "\n",
    "# Override the forward method with our patched version.\n",
    "MistralRotaryEmbedding.forward = patched_forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "752566a9-cb23-42d5-88f9-0ffa269212a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA parameters prepared. Number of trainable parameters: 6815744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/peft/mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## 2. Prepare the Model for Efficient Fine-Tuning using LoRA\n",
    "#\n",
    "# We use PEFT’s LoRA to fine-tune only a small subset of parameters.\n",
    "# The target modules (\"q_proj\" and \"v_proj\") may be adjusted based on the model's implementation.\n",
    "\n",
    "# %% Prepare the model for LoRA fine-tuning\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],  # Adjust if necessary\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "print(\"LoRA parameters prepared. Number of trainable parameters:\",\n",
    "      sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7da0ae77-d657-4ac0-90ec-8d014df4d3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'pytorch'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning repository https://github.com/pytorch/pytorch.git ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating files: 100% (19234/19234), done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 120 markdown files in pytorch.\n",
      "Cloning repository https://github.com/tensorflow/docs.git ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'tensorflow_docs'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 112 markdown files in tensorflow_docs.\n",
      "Cloning repository https://github.com/scikit-learn/scikit-learn.git ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'scikit-learn'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 markdown files in scikit-learn.\n",
      "Cloning repository https://github.com/pandas-dev/pandas.git ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'pandas'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 markdown files in pandas.\n",
      "\n",
      "Total collected and cleaned markdown documents: 236\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## 3. Data Collection, Cleansing, and Transformation\n",
    "#\n",
    "# We collect technical documentation from two GitHub repositories:\n",
    "# - PyTorch (docs in the `docs/` folder)\n",
    "# - TensorFlow Docs (markdown files at the root and subdirectories)\n",
    "\n",
    "# %% Define GitHub repositories to clone and process\n",
    "github_repos = [\n",
    "    {\"name\": \"pytorch\", \"url\": \"https://github.com/pytorch/pytorch.git\", \"docs_path\": \"docs\"},\n",
    "    {\"name\": \"tensorflow_docs\", \"url\": \"https://github.com/tensorflow/docs.git\", \"docs_path\": \"\"},\n",
    "    {\"name\": \"scikit-learn\", \"url\": \"https://github.com/scikit-learn/scikit-learn.git\", \"docs_path\": \"doc\"},\n",
    "    {\"name\": \"pandas\", \"url\": \"https://github.com/pandas-dev/pandas.git\", \"docs_path\": \"doc\"},\n",
    "    # Add more repositories as needed...\n",
    "]\n",
    "\n",
    "data_texts = []\n",
    "\n",
    "for repo in github_repos:\n",
    "    repo_dir = repo[\"name\"]\n",
    "    if not os.path.exists(repo_dir):\n",
    "        print(f\"Cloning repository {repo['url']} ...\")\n",
    "        os.system(f\"git clone {repo['url']} {repo_dir}\")\n",
    "    else:\n",
    "        print(f\"Repository {repo['name']} already cloned.\")\n",
    "\n",
    "    # Use the docs_path if provided; otherwise search the repo root.\n",
    "    search_dir = os.path.join(repo_dir, repo[\"docs_path\"]) if repo[\"docs_path\"] else repo_dir\n",
    "\n",
    "    # Recursively find Markdown files (*.md)\n",
    "    md_files = glob.glob(os.path.join(search_dir, \"**/*.md\"), recursive=True)\n",
    "    print(f\"Found {len(md_files)} markdown files in {repo['name']}.\")\n",
    "\n",
    "    for file_path in md_files:\n",
    "        try:\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                text = f.read()\n",
    "                # Remove code blocks (content between triple backticks)\n",
    "                text = re.sub(r'```.*?```', '', text, flags=re.DOTALL)\n",
    "                # Remove extra whitespace\n",
    "                text = re.sub(r'\\s+', ' ', text)\n",
    "                data_texts.append(text.strip())\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file_path}: {e}\")\n",
    "\n",
    "print(f\"\\nTotal collected and cleaned markdown documents: {len(data_texts)}\")\n",
    "\n",
    "# %% Create a Dataset from the collected texts\n",
    "df = pd.DataFrame({\"text\": data_texts})\n",
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05893174-08c3-4d49-9521-5de4deb1abf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7237fd1a7c1142ecbba01bb92c384f80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/236 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization complete.\n",
      "Train/evaluation split complete.\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## 4. Tokenization and Dataset Preparation\n",
    "#\n",
    "# We tokenize the documents, truncating them to 512 tokens.\n",
    "# (For larger documents, consider using a sliding window approach.)\n",
    "\n",
    "# %% Tokenize the dataset\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, max_length=512)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
    "print(\"Tokenization complete.\")\n",
    "\n",
    "# Split the dataset into train (90%) and evaluation (10%) sets.\n",
    "split_dataset = tokenized_dataset.train_test_split(test_size=0.1)\n",
    "print(\"Train/evaluation split complete.\")\n",
    "\n",
    "# Create a data collator for causal language modeling (no masking).\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16f2cf50-c7ed-4575-a85b-537fb766257a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fine-tuning...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='159' max='159' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [159/159 02:59, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.700500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.517100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.386300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=159, training_loss=1.5338380621664178, metrics={'train_runtime': 180.8236, 'train_samples_per_second': 3.517, 'train_steps_per_second': 0.879, 'total_flos': 1.376172494635008e+16, 'train_loss': 1.5338380621664178, 'epoch': 3.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## 5. Fine-Tuning the Model\n",
    "#\n",
    "# We define training arguments and initialize the Hugging Face Trainer.\n",
    "\n",
    "# %% Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./mistral_finetuned\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "#    evaluation_strategy=\"epoch\",\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-4,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    fp16=True,  # Mixed-precision training (CUDA environment)\n",
    "    logging_steps=50,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "# %% Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=split_dataset[\"train\"],\n",
    "    eval_dataset=split_dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# %% Start fine-tuning\n",
    "print(\"Starting fine-tuning...\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9da78b3d-3449-4cad-89eb-3e1c314414b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12efa95dc7444cf89b428cb07a146014",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Base Model Output ###\n",
      "\n",
      "Generate detailed technical documentation for a Python function that implements a 2D convolution operation for image processing.\n",
      "    \n",
      "The documentation should include:\n",
      "- **Problem Statement:** A clear description of the purpose of the function.\n",
      "- **Algorithm Explanation:** A detailed explanation of how the 2D convolution is performed, including discussion on kernel size, padding, stride, and edge handling.\n",
      "- **Input/Output Specifications:** Information on the expected types and shapes of inputs (e.g., image matrices, kernel arrays) and the output.\n",
      "- **Code Examples:** Illustrative code examples that include comments explaining each part of the code.\n",
      "- **Performance Analysis:** A brief discussion on the computational complexity and any optimization considerations.\n",
      "\n",
      "Provide the answer in markdown format with proper sections and code blocks.\n",
      "\n",
      "### Example\n",
      "\n",
      "```\n",
      "# Problem Statement\n",
      "\n",
      "The function implements 2D convolution operation for image processing.\n",
      "\n",
      "# Algorithm Explanation\n",
      "\n",
      "The function performs 2D convolution operation on an image matrix with a specified kernel.\n",
      "The operation involves sliding a kernel over the image matrix and performing element-wise multiplication of the kernel and the image matrix at each position,\n",
      "summing up the results, and adding the result to the accumulator.\n",
      "The convolution is performed for all possible positions of the kernel in the image matrix.\n",
      "\n",
      "# Input/Output Specifications\n",
      "\n",
      "The function takes as input image matrix and kernel array.\n",
      "The image matrix is a 2D array of shape (h, w) representing the image, where h is the height and w is the width.\n",
      "The kernel array is a 2D array of shape (k, k) representing the convolution kernel, where k is the size of the kernel.\n",
      "The function returns a 2D array of shape (h - k + 1, w - k + 1) representing the convolved image.\n",
      "\n",
      "# Code Examples\n",
      "\n",
      "# Performance Analysis\n",
      "\n",
      "The computational complexity of the function is O(h * w * k^2) where h and w are the height and width of the image,\n",
      "and k is the size of the kernel.\n",
      "The function can be optimized by using a faster\n",
      "\n",
      "### Fine-Tuned Model Output ###\n",
      "\n",
      "Generate detailed technical documentation for a Python function that implements a 2D convolution operation for image processing.\n",
      "    \n",
      "The documentation should include:\n",
      "- **Problem Statement:** A clear description of the purpose of the function.\n",
      "- **Algorithm Explanation:** A detailed explanation of how the 2D convolution is performed, including discussion on kernel size, padding, stride, and edge handling.\n",
      "- **Input/Output Specifications:** Information on the expected types and shapes of inputs (e.g., image matrices, kernel arrays) and the output.\n",
      "- **Code Examples:** Illustrative code examples that include comments explaining each part of the code.\n",
      "- **Performance Analysis:** A brief discussion on the computational complexity and any optimization considerations.\n",
      "\n",
      "Provide the answer in markdown format with proper sections and code blocks. Also, include all the necessary imports and libraries used.\n",
      "\n",
      "## Note:\n",
      "Please, be mindful of the [Markdown syntax](https://docs.github.com/en/github/writing-on-github/working-with-advanced-formatting/basic-writing-and-formatting-syntax).\n",
      "\n",
      "## Rules:\n",
      "- All submissions must adhere to the rules of conduct.\n",
      "- You can submit more than one answer, but please consult the [fairness policy](https://www.kaggle.com/code/competition-rules#code-submissions) before doing so.\n",
      "- Submissions must be your own work.\n",
      "- Submissions must be relevant to the task.\n",
      "- Submissions must be written in English.\n",
      "\n",
      "## Judging Criteria:\n",
      "- Clarity and organization of the documentation.\n",
      "- Quality and depth of the algorithm explanation.\n",
      "- Completeness and accuracy of the input/output specifications.\n",
      "- Effectiveness of the code examples in conveying the purpose of the function.\n",
      "- Insightfulness of the performance analysis.\n",
      "\n",
      "## Submission Instructions:\n",
      "1. Read the [prompt](https://docs.google.com/document/d/1oQhbz33K4j0b23g91wPn40b45z-2N6D\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## 6. Evaluation: Comparing the Fine-Tuned Model with the Base Model\n",
    "#\n",
    "# We compare the outputs of the fine-tuned model and the base model on a technical documentation prompt.\n",
    "\n",
    "# %% Define a helper function to generate text from a prompt\n",
    "def generate_text(model, prompt, max_new_tokens=300):\n",
    "    # Get the device from the model's parameters.\n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    # Tokenize the prompt.\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    # Move each tensor to the device.\n",
    "    inputs = {key: tensor.to(device) for key, tensor in inputs.items()}\n",
    "    \n",
    "    # Generate text using the model.\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "    # Decode and return the generated tokens.\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "prompt = (\n",
    "    \"\"\"Generate detailed technical documentation for a Python function that implements a 2D convolution operation for image processing.\n",
    "    \n",
    "The documentation should include:\n",
    "- **Problem Statement:** A clear description of the purpose of the function.\n",
    "- **Algorithm Explanation:** A detailed explanation of how the 2D convolution is performed, including discussion on kernel size, padding, stride, and edge handling.\n",
    "- **Input/Output Specifications:** Information on the expected types and shapes of inputs (e.g., image matrices, kernel arrays) and the output.\n",
    "- **Code Examples:** Illustrative code examples that include comments explaining each part of the code.\n",
    "- **Performance Analysis:** A brief discussion on the computational complexity and any optimization considerations.\n",
    "\n",
    "Provide the answer in markdown format with proper sections and code blocks.\"\"\"\n",
    ")\n",
    "# Load the base model (without fine-tuning adaptations) for comparison.\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    use_auth_token=my_token\n",
    ")\n",
    "\n",
    "print(\"### Base Model Output ###\\n\")\n",
    "print(generate_text(base_model, prompt))\n",
    "\n",
    "print(\"\\n### Fine-Tuned Model Output ###\\n\")\n",
    "print(generate_text(model, prompt))\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Conclusion\n",
    "#\n",
    "# In this notebook, we:\n",
    "# - Loaded a Mistral model in 4‑bit mode using BitsAndBytes on a CUDA environment.\n",
    "# - Prepared the model for efficient fine‑tuning using LoRA.\n",
    "# - Collected and cleaned technical documentation data from GitHub.\n",
    "# - Tokenized and prepared a dataset.\n",
    "# - Fine-tuned the model on the collected data.\n",
    "# - Compared the outputs from the fine-tuned model and the original base model.\n",
    "#\n",
    "# Experiment further with additional repositories, data cleansing methods, and hyperparameter settings to tailor the model to your specific needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ea727b-70c5-4ef0-9a9d-541837ba51ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
